{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRI+HEQHsV6GZZ8dBMkeiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeprogredire/tensorflow/blob/main/cnn_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download the dataset"
      ],
      "metadata": {
        "id": "gG26sJx9tSfa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmMP3oIqtC6t",
        "outputId": "85bc90ba-b68f-4275-a3b6-4e095972152f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-11 14:19:43--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.250.153.207, 142.250.145.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘horse-or-human.zip’\n",
            "\n",
            "horse-or-human.zip  100%[===================>] 142.65M  35.6MB/s    in 4.9s    \n",
            "\n",
            "2024-04-11 14:19:48 (29.0 MB/s) - ‘horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the training set\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the validation set\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2U0X9g5tXZG",
        "outputId": "0ddac454-b4bc-4274-b7a6-213a4f327510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-11 14:20:08--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.250.153.207, 142.250.145.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘validation-horse-or-human.zip’\n",
            "\n",
            "validation-horse-or 100%[===================>]  10.95M  12.5MB/s    in 0.9s    \n",
            "\n",
            "2024-04-11 14:20:09 (12.5 MB/s) - ‘validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip both the archives"
      ],
      "metadata": {
        "id": "IS8Wr2M8uBVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "#unzip training set\n",
        "local_zip='./horse-or-human.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('./horse-or-human')\n",
        "\n",
        "#unzip validation set\n",
        "local_zip='./validation-horse-or-human.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('./validation-horse-or-human')\n",
        "\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "AI983LPFuHN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Model"
      ],
      "metadata": {
        "id": "icM0Shwyvywu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(300,300,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "UxDsfk4gvPnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq8voddE2WGu",
        "outputId": "50dd0c7b-1bb4-4a86-a286-bc10d6a16fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 149, 149, 16)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 35, 35, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 78400)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               40141312  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40165409 (153.22 MB)\n",
            "Trainable params: 40165409 (153.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(learning_rate=0.001),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QNctj9GI2bHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "K0Gk5u-GlbPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# scaling all images\n",
        "train_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "validation_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "#Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    './horse-or-human',\n",
        "    target_size=(300,300),\n",
        "    batch_size=128,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "#Flow validation images in batches of 128 using validation_datagen generator\n",
        "validation_generator=validation_datagen.flow_from_directory(\n",
        "    './validation-horse-or-human',\n",
        "    target_size=(300,300),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_NcoMk-jVBB",
        "outputId": "949ce48d-459d-4147-922b-b99e40cb3ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "RXwqo_mQnOQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_generator,\n",
        "                  steps_per_epoch=8,\n",
        "                  epochs=15,\n",
        "                  verbose=1,\n",
        "                  validation_data=validation_generator,\n",
        "                  validation_steps=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zac55zWznNjC",
        "outputId": "87ea9923-339d-4041-9ca3-07a9acf42f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "8/8 [==============================] - 21s 1s/step - loss: 3.1823 - accuracy: 0.4883 - val_loss: 0.7267 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.6531 - accuracy: 0.6385 - val_loss: 0.5377 - val_accuracy: 0.8555\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.5323 - accuracy: 0.7564 - val_loss: 1.2435 - val_accuracy: 0.5039\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.3950 - accuracy: 0.8109 - val_loss: 0.3335 - val_accuracy: 0.8945\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.2203 - accuracy: 0.9155 - val_loss: 0.6815 - val_accuracy: 0.8086\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.2432 - accuracy: 0.8988 - val_loss: 0.9508 - val_accuracy: 0.7422\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.4516 - accuracy: 0.8988 - val_loss: 0.7623 - val_accuracy: 0.7344\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1509 - accuracy: 0.9499 - val_loss: 1.1566 - val_accuracy: 0.7109\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.0638 - accuracy: 0.9833 - val_loss: 1.4853 - val_accuracy: 0.7070\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1403 - accuracy: 0.9477 - val_loss: 1.2691 - val_accuracy: 0.7656\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.0530 - accuracy: 0.9854 - val_loss: 1.1974 - val_accuracy: 0.7891\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.0296 - accuracy: 0.9922 - val_loss: 1.2441 - val_accuracy: 0.8047\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.4095 - accuracy: 0.8487 - val_loss: 1.3023 - val_accuracy: 0.7109\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.0389 - accuracy: 0.9944 - val_loss: 1.0313 - val_accuracy: 0.8242\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.0233 - accuracy: 0.9980 - val_loss: 1.9092 - val_accuracy: 0.7109\n"
          ]
        }
      ]
    }
  ]
}